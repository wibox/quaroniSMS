{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from preprocessing import *\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from time import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf formatted_data\n",
    "! rm -rf complete_test_data\n",
    "! rm -rf complete_training_data\n",
    "! rm -rf complete_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_time = 3\n",
    "window_length = 3\n",
    "overlap_size = 1 #seconds\n",
    "strategy = \"window\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio files informations...\n",
      "Found 399 audio files.\n",
      "Cropping audio files to 3 seconds before and after passing time. Saving to ./formatted_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/399 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbenghus/Desktop/quaroniSMS/preprocessing.py:148: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  input_audiofile = siw.read(audio_path)\n",
      "  3%|▎         | 10/399 [00:00<00:04, 91.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/399 [00:00<00:04, 94.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30/399 [00:00<00:03, 94.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/399 [00:00<00:03, 93.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 52/399 [00:00<00:03, 100.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 65/399 [00:00<00:03, 106.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 76/399 [00:00<00:03, 105.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 88/399 [00:00<00:02, 107.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 100/399 [00:00<00:02, 110.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 112/399 [00:01<00:02, 112.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 124/399 [00:01<00:02, 107.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 146/399 [00:01<00:02, 105.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 170/399 [00:01<00:02, 110.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 182/399 [00:01<00:02, 102.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 196/399 [00:01<00:01, 111.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 208/399 [00:01<00:01, 112.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 221/399 [00:02<00:01, 116.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 233/399 [00:02<00:01, 114.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 245/399 [00:02<00:01, 112.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 257/399 [00:02<00:01, 112.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 269/399 [00:02<00:01, 114.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 282/399 [00:02<00:00, 117.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 294/399 [00:02<00:00, 113.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 306/399 [00:02<00:00, 108.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 328/399 [00:03<00:00, 106.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 352/399 [00:03<00:00, 106.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 375/399 [00:03<00:00, 107.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [00:03<00:00, 108.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n",
      "(1152000, 2) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = DatasetFormatter(crop_time=crop_time, window_length=window_length, overlap_size=overlap_size)\n",
    "df.format_dataset(strategy=\"window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir complete_training_data\n",
    "! mkdir complete_validation_data\n",
    "! mkdir complete_test_data\n",
    "\n",
    "! mv formatted_data/formatted_VWPassat/* complete_test_data\n",
    "! mv formatted_data/formatted_CitroenC4Picasso/* complete_validation_data\n",
    "! mv formatted_data/*/* complete_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: saved_models/*\n",
      "zsh:1: no matches found: tflite_models/*\n"
     ]
    }
   ],
   "source": [
    "! rm -rf saved_models/*\n",
    "! rm -rf tflite_models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(SHAPE, alpha, num_hidden_layers):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=SHAPE))\n",
    "    for layer_counter in range(num_hidden_layers):\n",
    "        if layer_counter == 0:\n",
    "            model.add(tf.keras.layers.Conv2D(filters=128*alpha, kernel_size=[3, 3], strides=[2, 2],\n",
    "                use_bias=False, padding='valid'))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Conv2D(filters=128*alpha, kernel_size=[3, 3], strides=[1, 1],\n",
    "                use_bias=False, padding='same'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(tf.keras.layers.Dense(units=len(LABELS)))\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible configurations found: 512\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {\n",
    "    'frame_length_in_s': [0.02, 0.04], #[0.02,0.04,0.06,0.08],\n",
    "    'frame_step_in_s': [0.01, 0.02], #[0.005, 0.01, 0.015, 0.02],\n",
    "    'num_mel_bins': [10, 20], #[20, 30, 40],\n",
    "    'lower_frequency': [15, 20], #[10,20,30],\n",
    "    'upper_frequency': [30, 60], #[3000, 4000, 5000],\n",
    "    'batch_size': [5, 7], #[10, 20, 30],\n",
    "    'epochs': [10, 15], #[10, 20, 30],\n",
    "    'initial_learning_rate': [0.01], #[0.005, 0.01, 0.02],\n",
    "    'end_learning_rate': [1.e-5], #[1.e-3, 1.e-5, 1.e-6],\n",
    "    'num_mfccs_features' : [-1], #[10, 15, -1]\n",
    "    'alpha': [0.1, 0.15], #[0.15, 0.25, 0.33]\n",
    "    'num_hidden_layers':[5, 7]\n",
    "}\n",
    "\n",
    "configurations = {\"configurations\": []}\n",
    "my_configs = ParameterGrid(PARAMS)\n",
    "for config in my_configs:\n",
    "    configurations[\"configurations\"].append(config)\n",
    "\n",
    "print(\"Possible configurations found: {}\".format(len(configurations[\"configurations\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log_header_to_csv(filename : str, header : str) -> bool:\n",
    "    completed = False\n",
    "    try:\n",
    "        with open(filename, \"w\") as header_fp:\n",
    "            header_fp.write(header + \"\\n\")\n",
    "        completed = True\n",
    "    except Exception as e:\n",
    "        print(e.format_exc())\n",
    "    finally:\n",
    "        return completed\n",
    "\n",
    "def _log_output_to_csv(filename : str, content : str) -> bool:\n",
    "    completed = False\n",
    "    try:\n",
    "        with open(filename, \"a\") as log_fp:\n",
    "            log_fp.write(content + \"\\n\")\n",
    "        completed = True\n",
    "    except Exception as e:\n",
    "        print(e.format_exc())\n",
    "    finally:\n",
    "        return completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'batch_size': 5, 'end_learning_rate': 1e-05, 'epochs': 10, 'frame_length_in_s': 0.02, 'frame_step_in_s': 0.01, 'initial_learning_rate': 0.01, 'lower_frequency': 15, 'num_hidden_layers': 5, 'num_mel_bins': 10, 'num_mfccs_features': -1, 'upper_frequency': 30}\n",
      "(5, 32, 32, 1)\n",
      "tf.Tensor([1 2 2 2 2], shape=(5,), dtype=int64)\n",
      "Epoch 1/10\n",
      "35/69 [==============>...............] - ETA: 45s - loss: 1.0194 - sparse_categorical_accuracy: 0.4743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/512 [00:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb Cella 10\u001b[0m in \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb#X12sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [tfmot\u001b[39m.\u001b[39msparsity\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mUpdatePruningStep()]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb#X12sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m model_for_pruning\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss, optimizer\u001b[39m=\u001b[39moptimizer, metrics\u001b[39m=\u001b[39mmetrics)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb#X12sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m history \u001b[39m=\u001b[39m model_for_pruning\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49mepoch, validation_data\u001b[39m=\u001b[39;49mvalidation_ds, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb#X12sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# computing statistics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb#X12sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sbenghus/Desktop/quaroniSMS/training_cnn_pg.ipynb#X12sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m training_loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/quaroniSMS/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "header = ','.join(k for k in PARAMS.keys()) + \",\" + ','.join([\n",
    "    \"accuracy\", \"avg_preprocessing_latency\", \"avg_model_latency\", \\\n",
    "         \"median_total_latency\", \"model_size\", \"compressed_model_size\"\n",
    "         ])\n",
    "\n",
    "_log_header_to_csv(filename=f\"{strategy}_cnn_results.csv\", header=header)\n",
    "\n",
    "train_file_ds = tf.data.Dataset.list_files(['complete_training_data/*.wav'])\n",
    "validation_file_ds = tf.data.Dataset.list_files(['complete_validation_data/*.wav'])\n",
    "test_file_ds = tf.data.Dataset.list_files(['complete_test_data/*.wav'])\n",
    "\n",
    "for idx in tqdm(range(len(configurations[\"configurations\"]))):\n",
    "    config = configurations[\"configurations\"][idx]\n",
    "    print(config)\n",
    "\n",
    "    MEL_LOG_ARGS = {\n",
    "        'frame_length_in_s': config['frame_length_in_s'],\n",
    "        'frame_step_in_s': config['frame_step_in_s'],\n",
    "        'num_mel_bins': config['num_mel_bins'],\n",
    "        'lower_frequency': config['lower_frequency'],\n",
    "        'upper_frequency': config['upper_frequency']\n",
    "    }\n",
    "    TRAINING_ARGS= {\n",
    "        'batch_size': config['batch_size'],\n",
    "        'epochs': config['epochs'],\n",
    "        'initial_learning_rate': config['initial_learning_rate'],\n",
    "        'end_learning_rate': config['end_learning_rate']\n",
    "    }\n",
    "\n",
    "    batch_size = TRAINING_ARGS['batch_size']\n",
    "    epoch = TRAINING_ARGS['epochs']\n",
    "\n",
    "\n",
    "    get_frozen_log_mel_spectrogram = partial(get_log_mel_spectrogram, **MEL_LOG_ARGS)\n",
    "    train_mel_ds = train_file_ds.map(get_frozen_log_mel_spectrogram)\n",
    "\n",
    "    for spectrogram, label in train_mel_ds.take(1):\n",
    "        SHAPE = spectrogram.shape\n",
    "\n",
    "    def preprocess_with_resized_mel(filename):\n",
    "        log_mel_spectrogram, label = get_frozen_log_mel_spectrogram(filename)\n",
    "        log_mel_spectrogram.set_shape(SHAPE)\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)[..., :]\n",
    "        mfccs = tf.expand_dims(mfccs, -1)\n",
    "        mfccs = tf.image.resize(mfccs, [32, 32])\n",
    "        label_id = tf.argmax(label == LABELS)\n",
    "\n",
    "        return mfccs, label_id\n",
    "\n",
    "    train_ds = train_file_ds.map(preprocess_with_resized_mel).batch(batch_size)\n",
    "    validation_ds = validation_file_ds.map(preprocess_with_resized_mel).batch(batch_size)\n",
    "    #test_ds = test_file_ds.map(preprocess_with_resized_mel).batch(batch_size)\n",
    "\n",
    "    for example_batch, example_labels in train_ds.take(1):\n",
    "        print(example_batch.shape)\n",
    "        print(example_labels)\n",
    "\n",
    "    model = get_model(SHAPE=example_batch.shape[1:], alpha=config['alpha'], num_hidden_layers=config['num_hidden_layers'])\n",
    "    # model.summary()\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "    begin_step = int(len(train_ds) * epoch * 0.2)\n",
    "    end_step = int(len(train_ds) * epoch)\n",
    "    final_sparsity=0.70\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.20,\n",
    "            final_sparsity=final_sparsity,\n",
    "            begin_step=begin_step,\n",
    "            end_step=end_step\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    initial_learning_rate = TRAINING_ARGS['initial_learning_rate']\n",
    "    end_learning_rate = TRAINING_ARGS['end_learning_rate']\n",
    "\n",
    "    linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        end_learning_rate=end_learning_rate,\n",
    "        decay_steps=len(train_ds) * epoch,\n",
    "    )\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=linear_decay)\n",
    "    metrics = [tf.metrics.SparseCategoricalAccuracy()]\n",
    "    callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    "    model_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    history = model_for_pruning.fit(train_ds, epochs=epoch, validation_data=validation_ds, callbacks=callbacks)\n",
    "    # computing statistics\n",
    "    # test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)\n",
    "    training_loss = history.history['loss'][-1]\n",
    "    training_accuracy = history.history['sparse_categorical_accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n",
    "    timestamp = int(time())\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    saved_model_dir = f'./saved_models/{timestamp}'\n",
    "    if not os.path.exists(saved_model_dir):\n",
    "        os.makedirs(saved_model_dir)\n",
    "    model_for_export.save(saved_model_dir)\n",
    "\n",
    "    # model conversion to tf-lite format\n",
    "    MODEL_NAME = timestamp\n",
    "    ZIPPED_MODEL_NAME = MODEL_NAME\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'./saved_models/{MODEL_NAME}')\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # saving tf-lite formatted model\n",
    "    tflite_models_dir = './tflite_models'\n",
    "    if not os.path.exists(tflite_models_dir):\n",
    "        os.makedirs(tflite_models_dir)\n",
    "    tflite_model_name = os.path.join(tflite_models_dir, f'{MODEL_NAME}.tflite')\n",
    "    with open(tflite_model_name, 'wb') as fp:\n",
    "        fp.write(tflite_model)\n",
    "\n",
    "    # save the zipped model\n",
    "    if not os.path.exists(\"./zipped_models\"):\n",
    "        os.makedirs(\"./zipped_models\")\n",
    "    with zipfile.ZipFile(f'{os.path.join(\"./zipped_models\",str(ZIPPED_MODEL_NAME))}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(tflite_model_name)\n",
    "\n",
    "    # performing inference\n",
    "    interpreter = tf.lite.Interpreter(model_path=f'tflite_models/{MODEL_NAME}.tflite')\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    avg_preprocessing_latency = 0.0\n",
    "    avg_model_latency = 0.0\n",
    "    latencies = []\n",
    "    accuracy = 0.0\n",
    "\n",
    "    start_map = time()\n",
    "    mapped_test_ds = test_file_ds.map(get_frozen_log_mel_spectrogram)\n",
    "    end_map =  time()\n",
    "    avg_map_time = (end_map - start_map)/len(test_file_ds)\n",
    "\n",
    "    # filenames = glob(\"complete_test_data/*.wav\")\n",
    "\n",
    "    # for fname in test_file_ds:\n",
    "    for log_mel_spectrogram, true_label in mapped_test_ds:\n",
    "\n",
    "        start_preprocess = time()\n",
    "\n",
    "        #log_mel_spectrogram, true_label = get_frozen_log_mel_spectrogram(fname)\n",
    "\n",
    "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)[..., :config['num_mfccs_features']]\n",
    "        mfccs = tf.expand_dims(mfccs, 0)\n",
    "        mfccs = tf.expand_dims(mfccs, -1)\n",
    "        mfccs = tf.image.resize(mfccs, [32, 32])\n",
    "\n",
    "        end_preprocess = time()\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], mfccs) \n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        end_inference = time()\n",
    "\n",
    "        top_index = np.argmax(output[0])\n",
    "        predicted_label = LABELS[top_index]\n",
    "\n",
    "        accuracy += true_label.numpy().decode() == predicted_label\n",
    "        avg_preprocessing_latency += avg_map_time + (end_preprocess - start_preprocess)\n",
    "        avg_model_latency += end_inference - end_preprocess\n",
    "        latencies.append(end_inference - start_preprocess)\n",
    "\n",
    "    accuracy /= len(mapped_test_ds)\n",
    "    avg_preprocessing_latency /= len(mapped_test_ds)\n",
    "    avg_model_latency /= len(mapped_test_ds)\n",
    "    median_total_latency = np.median(latencies)\n",
    "\n",
    "    model_size = os.path.getsize(f'tflite_models/{MODEL_NAME}.tflite')\n",
    "    compressed_model_size = os.path.getsize(f\"zipped_models/{ZIPPED_MODEL_NAME}.zip\")\n",
    "\n",
    "    content = f\"{config['frame_length_in_s']},\\\n",
    "        {config['frame_step_in_s']},{config['num_mel_bins']},\\\n",
    "            {config['lower_frequency']},{config['upper_frequency']},\\\n",
    "                {config['batch_size']},{config['epochs']},{config['initial_learning_rate']},\\\n",
    "                    {config['end_learning_rate']},{config['num_mfccs_features']},\\\n",
    "                        {config['alpha']},{100 * accuracy:.3f},{1000 * avg_preprocessing_latency:.1f},\\\n",
    "                            {1000 * avg_model_latency:.1f},{1000 * median_total_latency:.1f},\\\n",
    "                                {model_size / 2 ** 10:.1f},{compressed_model_size / 2 ** 10:.1f}\\n\"\n",
    "\n",
    "    _log_output_to_csv(filename=f\"{strategy}_cnn_results.csv\", content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e9cb38f4d69ed12a279fd49931a48d46a5ea383acdab751dc059544730dcd86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
